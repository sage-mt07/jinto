7. その他（共通観点）
 コードカバレッジ・テストケース命名・ドキュメントが一貫性を保っているか

 OSSユーザー・AI利用者向けに「設計意図・期待値・制約」が分かりやすく提示されているか

 鳴瀬/じんと/鏡花によるAI三権分立運用（自動生成/批判的レビュー/最終判定）が守られているか
7. その他（共通観点）
 コードカバレッジ・テストケース命名・ドキュメントが一貫性を保っているか

 OSSユーザー・AI利用者向けに「設計意図・期待値・制約」が分かりやすく提示されているか

 鳴瀬/じんと/鏡花によるAI三権分立運用（自動生成/批判的レビュー/最終判定）が守られているか
1. 命名規則と可読性
 テストクラス・テストメソッド名は「テスト対象＋動作＋期待値」が分かる命名か
（例：AddAsync_WithNullEntity_ThrowsArgumentNullException）

 Arrange/Act/Assertの三分構成、もしくはGiven/When/Thenパターンが明確になっているか

2. 独立性・副作用管理
 各テストは他テストに依存せず、単独実行/並列実行が可能か

 テスト終了後に状態がクリーンに戻る（クリーンアップ/Dispose/Resetが適切か）

 共有リソース（DB、Kafka、ファイル等）を使う場合、リソースの使い回し/衝突が発生しないか

3. カバレッジ・網羅性
 全ての主要な分岐（正常系・異常系・例外系）を網羅しているか

 バウンダリ値・境界条件・空/最大/最小データのテストがあるか

 Null許可/非許可、型不一致、属性不正等のテストがあるか

4. 可搬性・CI/CD対応
 CI環境・ローカル環境で同一結果になることを保証しているか

 テストデータが外部リソースに依存しすぎていないか（モック/スタブ/インメモリ利用の推奨）

 テストに外部API・ネットワーク等「テスト以外の要因で失敗する箇所」が無いか

5. 品質・形式
 末尾改行・BOMなし・文字コード（UTF-8等）の一貫性

 インデント・空行・コメント等、スタイル統一（.editorconfig等で自動化推奨）

 Assertメッセージ・テスト失敗時のエラーメッセージが明確で調査しやすいか

 テストコード自身の可読性・メンテナンス性（意味不明なマジックナンバー禁止）

6. メンテナンス・運用
 テストコードの「設計意図」「想定するユースケース」がコメント等で分かるか

 テスト失敗時の再現手順・原因切り分け方法がドキュメントされているか

 定期的なテストリファクタ・不要テストの削除/統合が運用設計に盛り込まれているか

7. AI・自動生成用追加観点（じんと/鏡花向け）
 自動生成テストの“レビュー観点”や“生成パターン”が一覧化されているか

 人手によるカスタマイズ/追加観点が自動生成ワークフローに反映できる仕組みがあるか

8.テストコードには必要なusingをすべて記載すること
9. 標準例外（ArgumentException など）を使う場合は `using System;` を記載するか完全修飾名を用いる
