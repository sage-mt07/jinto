# 詳細設計・運用ルール（Advanced Rules）

## 1. はじめに

本ドキュメントは `docs/guidelines.md` の詳細版として、設計思想の深掘りや高度な運用ルールをまとめています。  
基本ルールを理解した上で、より専門的な設定やカスタマイズを行う際に参照してください。

---

## 2. 命名規約の詳細

### 予約語の扱い

KafkaやksqlDBで予約されているキーワードはトピック名に使用しないことを推奨します。  
予約語の例には `SELECT`, `FROM`, `WHERE` などがあります。

### 命名衝突回避策

- トピック名やDLQ名の一意性を確保するため、開発チーム間での命名ルールを明確にし、管理することが重要です。  
- 同一環境内での重複トピック名は運用トラブルの原因となります。  

### 大文字小文字混在時の注意

- Kafkaはトピック名の大文字と小文字を区別しますが、慣例としてすべて小文字で統一することで人的ミスを減らせます。  

### マルチバイト・特殊文字の制限

- トピック名には英数字、ハイフン、アンダースコアのみを使用してください。  
- マルチバイト文字や空白、記号類は避けるべきです。

---

## 3. DLQ設計の深掘り

### DLQ投入ポリシーの細分化

- メッセージの処理失敗の種類に応じて、DLQ投入基準を明確に設定します。  
  例：  
  - デシリアライズエラー：即時DLQ投入  
  - ビジネスロジックエラー：リトライ後DLQ投入  
  - 一時的な外部依存エラー：リトライ優先  

### カスタムエラーコード設計

- DLQメッセージには標準的な`errorCode`に加え、システム固有のコードを付与することができます。  
- コード体系は事前に策定し、運用ドキュメントに明示してください。

### DLQの監視・アラート設計例

- DLQトピックのメッセージ量増加を監視し、閾値超過時に通知する仕組みを推奨します。  
- 早期検知により障害拡大を防止できます。

### メッセージ再処理フロー例

1. DLQからメッセージを抽出  
2. 原因分析と修正（スキーマ更新、データ修正など）  
3. 元トピックまたは専用リトライトピックへ再投入  

#### DLQの構成単位に関するポリシー

DLQはトピックごとに個別に持たず、システム全体で1つの共通DLQトピックを使用します。  
個別管理を避ける理由は以下の通りです：

- 再処理運用上、失敗原因の多くが**構造的に共通**であり、個別トピックに分離する意味が薄い
- トピック別DLQにすると、**監視・通知・再送設計が煩雑化**する
- 共通DLQ内に `sourceTopic` 等のメタ情報を付与することで**セグメント的な扱いが可能**

この設計により、**シンプルで安定した障害対応基盤**を維持しつつ、スケーラビリティも確保できます。

#### DLQトピック名の命名ルール

DLQトピックはシステム全体で1つに統一されることを前提とし、以下のような命名をデフォルトとします。

- デフォルト命名：`system.dlq`
- 環境ごとの識別が必要な場合は `system.dlq.dev` や `system.dlq.prd` の形式を使用
- 命名は小文字・ピリオド区切り・英数字のみ

> ※ この命名規則はデフォルトであり、`appsettings.json` または任意の構成ファイルにて上書き可能です。

構成例：

```json
{
  "Messaging": {
    "Dlq": {
      "Topic": "custom-app.dlq"
    }
  }
}

---

## 4. ストリーム/テーブル判定ロジック詳細

### LINQ式解析の技術的詳細

- LINQ式の解析により、GroupByやAggregate、Windowの有無を検出しテーブル判定を行います。  
- Expression Treeを用いて構文解析を行い、クエリ変換の基礎となります。

### 複合キー・複雑クエリの扱い

- 複数キーによるJOINや複雑なネストされた集約にも対応しています。  
- 内部的には式ツリーの分解・再構築を通じて正確なKSQL生成を実現します。

### 明示的指定の裏側実装説明

- `.AsStream()`や`.AsTable()`は解析結果の上書きを目的としており、優先度は高いです。  
- これらは内部的にフラグとして保存され、クエリ生成時に反映されます。

### 4.1 Window設計・マルチWindowパターン
1つのPOCOエンティティに対して、複数のウィンドウ（例：1, 5, 15, 60, 240分足）を同時適用できる。

設定ファイルの Windows 配列に指定することで、1つのKafkaトピック（例：trade-raw）から複数のWindow型StateStore（RocksDB）が自動生成される。これらのRocksDBストアは内部実装であり、利用者が直接操作することはない。

これによりPOCO定義の重複を防ぎ、運用負荷を低減できる。

### 4.2 命名規則（マルチWindow対応）
各StateStoreは自動的に {Entity名}_{Window値}min_Store 形式で命名される（例：TradeLogCandle_5min_Store）。

物理ディレクトリ名も同様に小文字化・記号変換したパターン（例：tradelogcandle_5min_store）。

設定で個別に StoreName を指定することで上書きも可能。

Kafka topic名は、1つの生データtopic（例：trade-raw）から複数のWindowが生成される場合、topic名はそのまま・Windowの識別はStore名で区別。

Window設計・マルチWindowパターン

1 POCO に対して複数 Window（例：1, 5, 15, 60, 240分足）を同時適用できる

設定ファイルの Windows 配列により 1 topic から複数の Window StateStore を自動生成

POCO重複を防ぎ運用負荷を低減

命名規則

自動的に {Entity名}_{Window値}min_Store

物理名は小文字・記号変換

topic名は生データtopicをそのまま使い、WindowはStore名で区別

さらに反映推奨する記述（宣言とアクセスの一貫性）
宣言（設定ファイル）もWindow、アクセス（IF）もWindow

例：context.TradeLogCandles.Window(5)

宣言・アクセスの一貫性を強調

追加例文案（追記用）
設定例：

```json
"Entities": [
  {
    "Entity": "TradeLogCandle",
    "SourceTopic": "trade-raw",
    "Windows": [1, 5, 15],
    "StoreType": "RocksDb"
  }
]
```
アクセス例：

```csharp
var oneMin = context.TradeLogCandles.Window(1).ToList();
var fiveMin = context.TradeLogCandles.Window(5).Where(...);
```
設定のWindow宣言とアクセスのWindow指定が一致し、拡張時も一貫した運用が可能。

4.3 x分足連続生成のためのHeartbeatトピック設計
背景と目的
x分足などの時系列ウィンドウデータは、元データトピック（例：trade-raw）に取引がない時間帯があると「空白期間」が発生し、足データの欠損となる。

これを防ぐため、Heartbeatトピックを新設し、Window定義ごとに毎秒ダミーレコードを送信する。

設計詳細
Heartbeat送信はWindowを宣言したEntity側が自動的に行う。

KafkaのHeartbeatトピックは
Key = {WindowType}:{yyyyMMddHHmmss} 形式（秒単位の丸め）で送信される。

複数podから同時送信されても、Kafka側でKeyが同一なら最新の1つだけが有効。

これにより、どんな分散運用でも「1秒につき1レコード」のみ維持され、負荷・重複送信を最小限に。

利用イメージ
Heartbeatレコードは「時刻」＋「WindowType」など最低限の情報のみ

足生成処理はHeatbeatも取り込むことで、取引のなかった期間の“空足”も確実に生成

TickデータはTickトピックでそのまま流し、Heatbeat対象外とする

サンプル構成
json
コピーする
編集する
"Entities": [
  {
    "Entity": "TradeLogCandle",
    "SourceTopic": "trade-raw",
    "Windows": [1, 5, 15, 60, 240],
    "Heartbeat": {
      "Topic": "trade-heartbeat",
      "IntervalSeconds": 1
    }
  }
]
サンプルコード（C#）
csharp
コピーする
編集する
var key = $"{windowType}:{DateTime.UtcNow:yyyyMMddHHmmss}";
producer.Produce("trade-heartbeat", new Message<string, Heartbeat> {
    Key = key,
    Value = new Heartbeat { WindowType = windowType, Timestamp = DateTime.UtcNow }
});
注意・運用ポイント
Keyの丸め単位は「秒」とすることで、秒足にも柔軟対応

足データは、Heatbeatがあることで常に連続時系列となり、グラフや集計でも“欠損穴”を生じにくい

100pod以上の分散環境でも負荷増加は無視できるレベル

---
## 5. ストリームとテーブルの簡単判定ルール

### 判定ロジックの概要

LINQ式の解析により、`GroupBy`、`Aggregate`、`Window` のいずれかが含まれている場合は **テーブルと判定** し、  
それ以外は **ストリームと判定** します。

この判定は内部で明確に実装されており、解析後に判定結果を取得・ログ出力できるため、  
利用者は自分のクエリがどちらに分類されているかを確認可能です。

### 明示的指定の優先度

- `.AsStream()` メソッドを使うと、判定結果にかかわらず強制的にストリームとして扱います。  
- `.AsTable()` メソッドを使うと、判定結果にかかわらず強制的にテーブルとして扱います。  
- 明示的指定は自動判定より優先されます。

### 利用上のポイント

- 自動判定に任せる場合は、`GroupBy` 等を含むクエリはテーブル処理になることを理解してください。  
- 特殊なケースや判定ミスを防ぐため、必要に応じて明示的指定を使い分けましょう。  
- 判定結果はデバッグログやAPI経由で取得し、開発中の確認に活用できます。


## 6. スキーマ管理と互換性戦略

### Avroスキーマ互換性モード解説

- `BACKWARD`：新スキーマは旧スキーマのデータを読み取れる必要があります。  
- `FORWARD`：旧スキーマは新スキーマのデータを読み取れる必要があります。  
- `FULL`：双方の互換性を保証します。  

### スキーマ進化時のベストプラクティス

- 互換性を維持するため、フィールドの削除や型変更は慎重に行います。  
- 新規フィールドはnullableにし、デフォルト値を設けることを推奨します。

### スキーマレジストリ運用ポリシー

- スキーマ登録はCI/CDパイプラインに組み込み、自動化を推奨します。  
- 互換性チェックの失敗はビルド失敗に連動させると安全です。

### スキーマレジストリ登録設計（補足）

- 本パッケージではスキーマの依存関係管理（依存スキーマの追跡や登録）は対象外とします。  
- 単一スキーマ単位での登録に集中し、複雑な依存関係はユーザー側で管理してください。  
- スキーマの登録・更新処理は、`Confluent.Kafka` クライアントライブラリを利用して実装します。  
- これにより、標準的なSchema RegistryのAPIを利用した安全で効率的な登録が可能です。


---

## 7. プロデュース/コンシュームの高信頼化

### Exactly Once Semantics (EOS)の考え方と実装制約

- KafkaのEOSはプロデューサーとコンシューマーの両方の協調が必要です。  
- 本ライブラリではプロデューサー側のトランザクション機能を利用可能ですが、ksqlDBは完全対応していません。  

### トランザクション処理の制限事項

- 複数トピック間の分散トランザクションは現状サポートされていません。  
- アプリケーション側で冪等性を確保する設計が必要です。

### 再送と重複排除のパターン

- メッセージキーを適切に設定し、コンシューマー側で重複排除を実装するパターンが一般的です。

---

## 8. CI/CD環境での構文検証モード

### 検証モードの内部動作解説

- Kafkaやスキーマレジストリに接続せず、LINQ DSLの構文とPOCOの妥当性のみを検証します。  
- 開発段階での早期エラー検出に役立ちます。

### ビルドパイプライン統合例

- CI環境での自動テストに組み込み、構文エラーを即座に検出可能です。  
- 失敗時にはビルドを中断し、修正を促します。

### エラー検出とフィードバックループ

- エラー内容はログに詳細に出力され、開発者に迅速にフィードバックされます。
- 修正サイクルを短縮し品質向上に寄与します。

### ForEachAsync のエラーハンドリング

`await foreach` を用いた購読処理では、各メッセージ取得時の例外を try-catch で捕捉します。
OnError ハンドラが設定されていればそれを呼び出し、未設定の場合はログ出力のみ行って次のメッセージへ進みます。
この挙動により、Kafka 側の一時的な障害や個別メッセージのデシリアライズ失敗があっても、ストリーム処理全体を中断せずに継続可能です。

---

## 9. 運用監視とトラブルシューティングの指針

（未記載：今後追加予定）

---

## 10. 拡張性とカスタマイズガイド

（未記載：今後追加予定）

---

## 11. 付録・用語集・参考文献

（未記載：今後追加予定）
